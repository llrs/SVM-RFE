---
title: "sge"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mRFE)
```


## Example SGE implementation

Included in the `sge` directory is an example custom parallel implementation using the SGE cluster interface. It will need to be modified to fit your own cluster setup, but I included it because looking through the code might give you some ideas.

- For the **feature ranking**, the external CV folds are parallelized.
- For the **generalization error estimating**, all the different runs with varying numbers of input features are parallelized.

### Setup notes

- A version of `Rscript` must be in your unix path. `Rscript` can be found in the `bin` directory of recent versions of R.
- These scripts are executed like shell scripts, so...
  - Make sure they are in your unix path (e.g. something like `PATH=/path/to/SVM-RFE/sge:$PATH` to add the `sge` directory to the path in bash).
  - Make sure they are executable (e.g. `chmod +x sge/*`).
- As written, these scripts use an excellent `qsub` wrapper called `fsl_sub` that is included with the [FSL](http://www.fmrib.ox.ac.uk/fsl/) neuroimaging toolset. If yours is different, you'll need to modify these calls accordingly.
- If `e1071` is installed, but there are error messages that it can't be found, you probably installed it in some user specific location. You can add this area to the default R search path by setting the `R_LIBS` unix environment variable.
- The main `msvmRFE.R` functions file is sourced in several of these scripts. It is setup to work relative to the `demo` directory, as downloaded, but you might want to hard-code your system-specific full path to this file so you don't always have to call it from the same directory.

### Usage

From within a directory with an `input.Rdata` file present, submit the feature ranking jobs from the unix command line.

```{r}
msvmRFE_submit.R nfold <- 10
1484221
1484222
Number of folds: 10

```

You can make sure your jobs are running smoothly with `qstat`.

```
$ watch qstat -u me
Every 2.0s: qstat -u me                                                                Wed Sep 14 10:30:03 2011

job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID
-----------------------------------------------------------------------------------------------------------------
1484221 0.50093 jobarray.t me           r     09/14/2011 11:20:44 pod_smp.q@n7261                    1 1
1484221 0.50046 jobarray.t me           r     09/14/2011 11:20:44 pod_smp.q@n6266                    1 2
1484221 0.50031 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n6228                    1 3
1484221 0.50023 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n6231                    1 4
1484221 0.50018 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n7225                    1 5
1484221 0.50015 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n6273                    1 6
1484221 0.50013 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n7223                    1 7
1484221 0.50012 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n6237                    1 8
1484221 0.50010 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n7231                    1 9
1484221 0.50009 jobarray.t me           r     09/14/2011 11:20:45 pod_smp.q@n6233                    1 10
1484222 0.00000 msvmRFE_co me           hqw   09/14/2011 11:19:42                                    1        
```

As expected, the 10 external cross validation folds are running in parallel, and 1 extra job is waiting to combine those results.

You can also check the progress of these jobs.

```
$ tail jobarray.txt.o*
==> jobarray.txt.o1484221.1 <==
Scaling data...Done!
  |===================================                                   |  49%
==> jobarray.txt.o1484221.10 <==
Scaling data...Done!
  |================================                                      |  46%
==> jobarray.txt.o1484221.2 <==
Scaling data...Done!
  |===================================                                   |  50%
==> jobarray.txt.o1484221.3 <==
Scaling data...Done!
  |========================================                              |  57%
==> jobarray.txt.o1484221.4 <==
Scaling data...Done!
  |================================                                      |  45%
==> jobarray.txt.o1484221.5 <==
Scaling data...Done!
  |=============================                                         |  41%
==> jobarray.txt.o1484221.6 <==
Scaling data...Done!
  |======================================                                |  54%
==> jobarray.txt.o1484221.7 <==
Scaling data...Done!
  |===================================                                   |  49%
==> jobarray.txt.o1484221.8 <==
Scaling data...Done!
  |=====================================                                 |  53%
==> jobarray.txt.o1484221.9 <==
Scaling data...Done!
  |======================================                                |  55%
```

Once these jobs have finished, you'll be left with a `results.Rdata` file, containing the results of the feature ranking for each of the external CV folds (like the interactive example, above), as well as a plain text version of the average feature rankings across all folds (`features_ranked.txt`).

Next, submit the generalization error estimation sweep over the top features.

```
$ featsweep_submit.R nfeat=1:5
1484244
1484245
Number of features to sweep: 5
```

Input arguments to Rscript get parsed as normal R expressions, so you can request a more complicated set if desired. For example:

```
$ featsweep_submit.R 'nfeat=c(1:100, seq(102, 500, by=2))'
```

When these jobs finish, you should have a `featsweep.Rdata` file, containing the obtimal tuning parameters and generalization error estimates for each combination of top features (like the interactive example, above), as well as 2 plots of the estimated generalization error vs. # of top features. 
